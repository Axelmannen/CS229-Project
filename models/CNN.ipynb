{"cells":[{"cell_type":"markdown","metadata":{"id":"URRRbyFF0j-Q"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6Y0c79yi6FD"},"outputs":[],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpkpYSgJ0j-T"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","import glob\n","import numpy as np\n","import os\n","import pandas as pd\n","import random\n","\n","import matplotlib.pyplot as plt\n","\n","import optuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX3BEdvA6hXf"},"outputs":[],"source":["\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using CPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgQY3sYi02LW"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"BrpAuoCP0j-W"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RPzbD0iLISQ0"},"outputs":[],"source":["\n","\n","class SpeedDataset(Dataset):\n","    def __init__(self, directory_paths, sequence_length):\n","        self.sequence_length = sequence_length\n","        sequences, labels, timestamps = self.load_data_from_directories(directory_paths)\n","        self.data = torch.tensor(sequences, dtype=torch.float32).transpose(1, 2)\n","        self.labels = torch.tensor(labels, dtype=torch.float32)\n","        self.timestamps = timestamps\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx]\n","\n","    def load_data_from_directories(self, directory_paths):\n","        all_sequences = None\n","        all_labels = None\n","        all_timestamps = None\n","        for dir_path in directory_paths:\n","            for filename in os.listdir(dir_path):\n","                if filename.endswith(\".csv\"):\n","                    file_path = os.path.join(dir_path, filename)\n","                    data = pd.read_csv(file_path, header=None, names=['timestamp', 'x_acc', 'y_acc', 'z_acc', 'gps_speed'])\n","                    sequences, labels, timestamps = self.create_sequences(data, self.sequence_length)\n","                    if all_sequences is None:\n","                        all_sequences = sequences\n","                        all_labels = labels\n","                        all_timestamps = timestamps\n","                    else:\n","                        all_sequences = np.concatenate((all_sequences, sequences), axis=0)\n","                        all_labels = np.concatenate((all_labels, labels), axis=0)\n","                        all_timestamps = np.concatenate((all_timestamps, timestamps), axis=0)\n","        return all_sequences, all_labels, all_timestamps\n","\n","    def create_sequences(self, data, sequence_length):\n","        sequences = []\n","        labels = []\n","        timestamps = []\n","\n","        for i in range(len(data) - sequence_length):\n","            seq = data.iloc[i:i+sequence_length][['x_acc', 'y_acc', 'z_acc']].values\n","            label = data.iloc[i:i+sequence_length]['gps_speed'].mean()\n","            sequences.append(seq)\n","            labels.append(label)\n","            timestamps.append(data.iloc[i]['timestamp'])\n","\n","        return np.array(sequences), np.array(labels), np.array(timestamps)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bB8HFGp1wDw2"},"outputs":[],"source":["# Create training and testing datasets\n","train_dir = ['/content/drive/Shareddrives/CS229/Data/FinalSplits/train_axel/']\n","eval_dir = ['/content/drive/Shareddrives/CS229/Data/FinalSplits/eval_axel/']\n","test_dir = ['/content/drive/Shareddrives/CS229/Data/FinalSplits/test_axel/']"]},{"cell_type":"markdown","metadata":{"id":"8RLXCvvBNNAU"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuDM5ZDBNVpL"},"outputs":[],"source":["\n","\n","class CNNModel(nn.Module):\n","    def __init__(self, conv1_filters, conv2_filters, dropout_rate, kernel_size):\n","        super(CNNModel, self).__init__()\n","        sequence_length = 40\n","        self.conv1 = nn.Conv1d(in_channels=3, out_channels=conv1_filters, kernel_size=kernel_size, stride=1, padding=kernel_size // 2)\n","        self.conv2 = nn.Conv1d(in_channels=conv1_filters, out_channels=conv2_filters, kernel_size=kernel_size, stride=1, padding=kernel_size // 2)\n","        self.fc1 = nn.Linear(conv2_filters * sequence_length, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.relu(self.conv2(x))\n","        x = x.view(x.size(0), -1)\n","        x = self.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SwGIbL2lipUi"},"source":["# Optimize Hyperparameters\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdG5OE6qinz3"},"outputs":[],"source":["def objective(trial):\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n","    sequence_length = 40\n","    conv1_filters = trial.suggest_int(\"conv1_filters\", 8, 64, step=8)\n","    conv2_filters = trial.suggest_int(\"conv2_filters\", 16, 128, step=16)\n","    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n","    kernel_size = trial.suggest_int(\"kernel_size\", 3, 7, step=2)\n","\n","\n","    model = CNNModel(conv1_filters, conv2_filters, dropout_rate, kernel_size).to(device)\n","\n","    train_dataset = SpeedDataset(train_dir, sequence_length)\n","    eval_dataset = SpeedDataset(eval_dir, sequence_length)\n","    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    X_eval_tensor = eval_dataset.data.to(device)\n","    y_eval_tensor = eval_dataset.labels.to(device)\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    max_epochs = 1000\n","    patience = 50\n","    best_eval_loss = float('inf')\n","    epochs_without_improvement = 0\n","\n","    for epoch in range(max_epochs):\n","        model.train()\n","        for X_batch, y_batch in train_loader:\n","            X_tensor = X_batch.to(device)\n","            y_tensor = y_batch.to(device)\n","\n","            optimizer.zero_grad()\n","            predictions = model(X_tensor).squeeze()\n","            loss = criterion(predictions, y_tensor)\n","            loss.backward()\n","            optimizer.step()\n","\n","        model.eval()\n","        with torch.no_grad():\n","            eval_predictions = model(X_eval_tensor).squeeze()\n","            eval_loss = criterion(eval_predictions, y_eval_tensor)\n","\n","        if eval_loss.item() < best_eval_loss:\n","            best_eval_loss = eval_loss.item()\n","            epochs_without_improvement = 0\n","        else:\n","            epochs_without_improvement += 1\n","\n","        if epochs_without_improvement >= patience:\n","            break\n","\n","    return best_eval_loss\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FDaTErrkP5f"},"outputs":[],"source":["study = optuna.create_study(direction='minimize')\n","study.optimize(objective, n_trials=20)\n","print(\"Best Hyperparameters:\", study.best_params)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AjRY8XPP0j-Y"},"source":["# Final training (using both training and eval data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOj7ZknL6MbD"},"outputs":[],"source":["lr = study.best_params[\"learning_rate\"]\n","sequence_length = 40\n","conv1_filters = study.best_params[\"conv1_filters\"]\n","conv2_filters = study.best_params[\"conv2_filters\"]\n","dropout_rate = study.best_params[\"dropout_rate\"]\n","kernel_size = study.best_params[\"kernel_size\"]\n","\n","batch_size = 32\n","\n","model = CNNModel(conv1_filters, conv2_filters, dropout_rate, kernel_size).to(device)\n","\n","train_dataset = SpeedDataset(train_dir + eval_dir, sequence_length)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","\n","max_epochs = 10000\n","epsillon = 0.001\n","\n","total_loss = 0.0\n","model.train()\n","for epoch in range(max_epochs):\n","\n","    previous_loss = total_loss\n","    total_loss = 0.0\n","    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n","        X_tensor = X_batch.to(device)\n","        y_tensor = y_batch.to(device)\n","\n","        predictions = model(X_tensor)\n","        predictions = torch.squeeze(predictions)\n","        loss = criterion(predictions, y_tensor)\n","        total_loss += loss.item()\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if abs(previous_loss - total_loss) < epsillon:\n","      break\n","\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch {epoch+1}/{max_epochs}, Total Loss: {total_loss:.4f}\")\n"]},{"cell_type":"code","source":["\n","\n","learning_rate = 0.0001\n","sequence_length = 40\n","conv1_filters = 32\n","conv2_filters = 16\n","dropout_rate = 0.0\n","kernel_size = 9\n","\n","train_dir = [\n","    '/content/drive/Shareddrives/CS229/Data/FinalSplits/train_axel/',\n","    '/content/drive/Shareddrives/CS229/Data/FinalSplits/train_jengchi/',\n","    ]\n","eval_dir = ['/content/drive/Shareddrives/CS229/Data/FinalSplits/eval_axel/']\n","\n","model = CNNModel(conv1_filters, conv2_filters, dropout_rate, kernel_size).to(device)\n","\n","train_dataset = SpeedDataset(train_dir, sequence_length)\n","eval_dataset = SpeedDataset(eval_dir, sequence_length)\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n","X_eval_tensor = eval_dataset.data.to(device)\n","y_eval_tensor = eval_dataset.labels.to(device)\n","\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","max_epochs = 1000\n","patience = 8\n","best_eval_loss = float('inf')\n","epochs_without_improvement = 0\n","\n","train_losses = []\n","eval_losses = []\n","\n","for epoch in range(max_epochs):\n","\n","    model.train()\n","    total_loss = 0.0\n","    for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n","        X_tensor = X_batch.to(device)\n","        y_tensor = y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","        predictions = model(X_tensor).squeeze()\n","        loss = criterion(predictions, y_tensor)\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    avg_train_loss = total_loss / len(train_loader)\n","    train_losses.append(avg_train_loss)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        eval_predictions = model(X_eval_tensor).squeeze()\n","        eval_loss = criterion(eval_predictions, y_eval_tensor)\n","        eval_losses.append(eval_loss.item())\n","\n","    print(f\"Epoch {epoch+1}/{max_epochs}, Train Loss: {total_loss:.4f}, Eval Loss: {eval_loss.item():.4f}\")\n","\n","    if eval_loss.item() < best_eval_loss:\n","        best_eval_loss = eval_loss.item()\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","\n","    if epochs_without_improvement >= patience:\n","        print(f\"Early stopping at epoch {epoch+1}\")\n","        break\n","\n","plt.figure(figsize=(12, 6))\n","plt.title('Training and Validation Losses')\n","plt.plot(train_losses, label='Training Loss', color='blue')\n","plt.plot(eval_losses, label='Validation Loss', color='red')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n"],"metadata":{"id":"nZav6pJbpU9f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"knCuYuLN0j-Z"},"source":["# Evaluation"]},{"cell_type":"markdown","metadata":{"id":"mStxamJxRBxM"},"source":["### Calculate Metrics\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2pd36O1Q9Ey"},"outputs":[],"source":["test_dir = ['/content/drive/Shareddrives/CS229/Data/FinalSplits/test_axel/']\n","\n","train_dataset = SpeedDataset(train_dir, sequence_length)\n","test_dataset = SpeedDataset(test_dir, sequence_length)\n","\n","model.eval()\n","\n","predicted_train = model(train_dataset.data.to(device)).detach()\n","predicted_train = torch.squeeze(predicted_train).to(device)\n","\n","predicted_test = model(test_dataset.data.to(device)).detach()\n","predicted_test = torch.squeeze(predicted_test).to(device)\n","\n","mse_train = (np.square(predicted_train.to(\"cpu\") - train_dataset.labels.numpy())).mean(axis=0)\n","mse_test = (np.square(predicted_test.to(\"cpu\") - test_dataset.labels.numpy())).mean(axis=0)\n","\n","print(f\"MSE Train: {mse_train}\")\n","print(f\"MSE Test: {mse_test}\")"]},{"cell_type":"markdown","metadata":{"id":"IT8d0bcKLSA0"},"source":["### Plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3xVzcXCMGYiW"},"outputs":[],"source":["predicted_test = model(test_dataset.data.to(device)).detach().to(\"cpu\").numpy()\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(test_dataset.timestamps, test_dataset.labels, label='Ground Truth GPS Speed', color='blue')\n","plt.plot(test_dataset.timestamps, predicted_test, label='Predicted GPS Speed', color='red')\n","plt.xlabel('Timestamp (ms since start)')\n","plt.ylabel('Speed (m/s)')\n","plt.title('Ground Truth vs. Predicted GPS Speed')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":6027555,"sourceId":9828395,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}